{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Condition number\n",
    "\n",
    "For a linear system, ${\\bf A x} = {\\bf b}$, we can only solve for $x$ if the determinant of the matrix ${\\bf A}$ is non-zero.  If the determinant is zero, then we call the matrix _singular_.  The _condition number_ of a matrix is a measure of how close we are to being singular.  The formal definition is:\n",
    "\\begin{equation}\n",
    "\\mathrm{cond}({\\bf A}) = \\| {\\bf A}\\| \\| {\\bf A}^{-1} \\|\n",
    "\\end{equation}\n",
    "But we can think of it as a measure of how much ${\\bf x}$ would change due to a small change in ${\\bf b}$.  A large condition number means that our solution for ${\\bf x}$ could be inaccurate.\n",
    "\n",
    "A _Hilbert matrix_ has $H_{ij} = (i + j + 1)^{-1}$, and is known to have a large condition number.  Here's a routine to generate a Hilbert matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hilbert(n):\n",
    "    \"\"\" return a Hilbert matrix, H_ij = (i + j - 1)^{-1} \"\"\"\n",
    "\n",
    "    H = np.zeros((n,n), dtype=np.float64)\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, n+1):\n",
    "            H[i-1,j-1] = 1.0/(i + j - 1.0)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's solve ${\\bf Hx} ={\\bf b}$.  Create a linear system by picking an ${\\bf x}$ and generating a ${\\bf b}$ by multiplying by the matrix ${\\bf H}$.  Then use the `scipy.linalg.solve()` function to recover ${\\bf x}$.  Compute the error in ${\\bf x}$ as a function of the size of the matrix.\n",
    "\n",
    "You won't need a large matrix, $n \\sim 13$ or so, will start showing big errors.\n",
    "\n",
    "You can compute the condition number with `numpy.linalg.cond()`\n",
    "\n",
    "There are methods that can do a better job with nearly-singular matricies.  Take a look at `scipy.linalg.lstsq()` for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import ode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: FFT of chaotic pendulum\n",
    "\n",
    "Last time we looked at ODEs and the chaotic pendulum, and were interested in writing a method to integrate the pendulum in time.\n",
    "\n",
    "Here we want to examine its behavior in frequency space.  The code below will integrate the chaotic pendulum using a fixed dt, which makes it suitable for taking the FFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhs(t, Y, q, omega_d, b):\n",
    "    \"\"\" damped driven pendulum system derivatives.  Here, Y = (theta, omega) are\n",
    "        the solution variables. \"\"\"\n",
    "    f = np.zeros_like(Y)\n",
    "        \n",
    "    f[0] = Y[1]\n",
    "    f[1] = -q*Y[1] - np.sin(Y[0]) + b*np.cos(omega_d*t)\n",
    "\n",
    "    return f\n",
    "\n",
    "def restrict_theta(theta):\n",
    "    \"\"\" convert theta to be restricted to lie between -pi and pi\"\"\"\n",
    "    tnew = theta + np.pi\n",
    "    tnew += -2.0*np.pi*np.floor(tnew/(2.0*np.pi))\n",
    "    tnew -= np.pi\n",
    "    return tnew\n",
    "\n",
    "def int_pendulum(theta0, q, omega_d, b, tend, dt):\n",
    "    \"\"\" integrate the pendulum with a fixed timestep, dt\"\"\"\n",
    "    r = ode(rhs)\n",
    "    r.set_integrator(\"dopri5\", nsteps=150000, first_step=dt, max_step=dt, dfactor=1.0)\n",
    "\n",
    "    sol = []\n",
    "    r.set_solout(lambda t, y: sol.append([t, *y]))\n",
    "\n",
    "    t0 = 0.0\n",
    "    omega0 = 0.0\n",
    "    r.set_initial_value((theta0, omega0), t0)\n",
    "\n",
    "    r.set_f_params(q, omega_d, b)\n",
    "\n",
    "    r.integrate(tend)\n",
    "    return np.array(sol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call below will give an undamped pendulum.  For a small amplitude, since we have $L = g$ in our pendulum, the period is simply $T = 2\\pi$, and the frequency is $\\nu_k = 1/(2\\pi)$.  We plot things in terms of angular frequency, $\\omega_k = 2\\pi \\nu_k$, so all the power will be at $\\omega_k = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = int_pendulum(np.radians(10), 0.0, 0.6666, 0.0, 200.0, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to complete the power spectrum routine below to calculate the FFT of theta and plot it.  Experiment with the damping and driving parameters to see the complexity of the pendulum in frequency space when it becomes chaotic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_spectrum(t, theta0):\n",
    "    \"\"\" return the power spectrum of theta.  For the frequency\n",
    "        component, return it in terms of omega \"\"\"\n",
    "\n",
    "    theta = restrict_theta(theta0)\n",
    "    \n",
    "    # fill in the rest -- take the FFT of theta and return omega_k and \n",
    "    # the transform of theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Let's find the errors on our fit\n",
    "\n",
    "We looked at fits, but not what the errors are on the fit.  Look at `scipy.optimize.curve_fit()`.  This is a simplified wrapper on the least squares fitting.  It can return the convariance matrix, the diagonals of which can give the error of the fit for the parameters.  \n",
    "\n",
    "Make up some data that models a non-linear function (by introducing some random noise) and perform a fit and find the errors on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
